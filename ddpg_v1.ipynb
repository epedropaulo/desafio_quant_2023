{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from nice_funcs.indicators import CreateRandomPrtf,EWMA,MACD,RSI,NormalizeWindow\n",
    "from ambiente import TradingEnv\n",
    "\n",
    "\n",
    "def GetIndex(*args):\n",
    "  indicators = [*args]\n",
    "  index_init = set(indicators[0].index)\n",
    "  for ind_ in indicators:\n",
    "    index_init = index_init & set(ind_.index)\n",
    "  \n",
    "  idx_date = min(index_init)\n",
    "  new_index_indicators = []\n",
    "  for ind_ in indicators:\n",
    "    ind_['Cash'] = 0 \n",
    "    new_index_indicators.append(ind_[idx_date:])\n",
    "  return new_index_indicators\n",
    "        \n",
    "\n",
    "\n",
    "# %%\n",
    "path_diario = './assets/1d/'\n",
    "ativos = os.listdir(path_diario)\n",
    "\n",
    "ativosOHLC = {}\n",
    "for ativo in ativos:\n",
    "    ativosOHLC[ativo.replace('.xlsx','')] = \\\n",
    "        pd.read_excel(os.path.join(path_diario,ativo),index_col=0)\n",
    "    \n",
    "\n",
    "close_prices = {}\n",
    "for k in ativosOHLC.keys():\n",
    "  close_prices[k] = ativosOHLC[k].Close\n",
    "\n",
    "\n",
    "df_fechamento = pd.DataFrame(close_prices).iloc[:-360]\n",
    "normalized_fech = df_fechamento.apply(lambda row: NormalizeWindow(row)).dropna()\n",
    "macd = normalized_fech.apply(lambda row: MACD(row)[0]).dropna()\n",
    "rsi = normalized_fech.apply(lambda row: RSI(row)).dropna()\n",
    "ewma_diff = normalized_fech.apply(lambda row: EWMA(row,20) - EWMA(row,5)).dropna()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_fechamento,normalized_fech,macd,rsi,ewma_diff =  GetIndex(df_fechamento,normalized_fech, macd, rsi, ewma_diff)\n",
    "\n",
    "\n",
    "env = TradingEnv(df_fechamento,[normalized_fech,macd,rsi,ewma_diff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADAUSDT</th>\n",
       "      <th>BNBUSDT</th>\n",
       "      <th>BTCUSDT</th>\n",
       "      <th>ETHUSDT</th>\n",
       "      <th>LTCUSDT</th>\n",
       "      <th>XRPUSDT</th>\n",
       "      <th>Cash</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-06-18</th>\n",
       "      <td>-1.103457</td>\n",
       "      <td>1.411699</td>\n",
       "      <td>-0.768851</td>\n",
       "      <td>-0.732371</td>\n",
       "      <td>-1.070490</td>\n",
       "      <td>-1.154540</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-19</th>\n",
       "      <td>-0.889136</td>\n",
       "      <td>1.337789</td>\n",
       "      <td>-0.651483</td>\n",
       "      <td>-0.300377</td>\n",
       "      <td>-0.973955</td>\n",
       "      <td>-0.923059</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-20</th>\n",
       "      <td>-0.982724</td>\n",
       "      <td>0.573641</td>\n",
       "      <td>-0.549649</td>\n",
       "      <td>-0.289839</td>\n",
       "      <td>-0.955627</td>\n",
       "      <td>-0.988063</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-21</th>\n",
       "      <td>-1.031417</td>\n",
       "      <td>1.458236</td>\n",
       "      <td>-0.561819</td>\n",
       "      <td>-0.449708</td>\n",
       "      <td>-0.940942</td>\n",
       "      <td>-0.968987</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-22</th>\n",
       "      <td>-1.608189</td>\n",
       "      <td>-0.168414</td>\n",
       "      <td>-1.631754</td>\n",
       "      <td>-1.562283</td>\n",
       "      <td>-1.715639</td>\n",
       "      <td>-1.574267</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-05</th>\n",
       "      <td>0.832198</td>\n",
       "      <td>2.062444</td>\n",
       "      <td>0.627964</td>\n",
       "      <td>1.425203</td>\n",
       "      <td>1.684018</td>\n",
       "      <td>0.847826</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-06</th>\n",
       "      <td>0.463622</td>\n",
       "      <td>1.777482</td>\n",
       "      <td>0.082091</td>\n",
       "      <td>0.958956</td>\n",
       "      <td>0.919183</td>\n",
       "      <td>0.413158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-07</th>\n",
       "      <td>1.333937</td>\n",
       "      <td>1.825976</td>\n",
       "      <td>0.351730</td>\n",
       "      <td>0.977090</td>\n",
       "      <td>0.953756</td>\n",
       "      <td>0.438750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-08</th>\n",
       "      <td>1.706034</td>\n",
       "      <td>1.664191</td>\n",
       "      <td>1.217720</td>\n",
       "      <td>1.617412</td>\n",
       "      <td>1.387682</td>\n",
       "      <td>0.908759</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-09</th>\n",
       "      <td>0.288694</td>\n",
       "      <td>1.461280</td>\n",
       "      <td>0.282806</td>\n",
       "      <td>0.740531</td>\n",
       "      <td>0.042061</td>\n",
       "      <td>0.010779</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1514 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ADAUSDT   BNBUSDT   BTCUSDT   ETHUSDT   LTCUSDT   XRPUSDT  Cash\n",
       "Date                                                                        \n",
       "2018-06-18 -1.103457  1.411699 -0.768851 -0.732371 -1.070490 -1.154540     0\n",
       "2018-06-19 -0.889136  1.337789 -0.651483 -0.300377 -0.973955 -0.923059     0\n",
       "2018-06-20 -0.982724  0.573641 -0.549649 -0.289839 -0.955627 -0.988063     0\n",
       "2018-06-21 -1.031417  1.458236 -0.561819 -0.449708 -0.940942 -0.968987     0\n",
       "2018-06-22 -1.608189 -0.168414 -1.631754 -1.562283 -1.715639 -1.574267     0\n",
       "...              ...       ...       ...       ...       ...       ...   ...\n",
       "2022-08-05  0.832198  2.062444  0.627964  1.425203  1.684018  0.847826     0\n",
       "2022-08-06  0.463622  1.777482  0.082091  0.958956  0.919183  0.413158     0\n",
       "2022-08-07  1.333937  1.825976  0.351730  0.977090  0.953756  0.438750     0\n",
       "2022-08-08  1.706034  1.664191  1.217720  1.617412  1.387682  0.908759     0\n",
       "2022-08-09  0.288694  1.461280  0.282806  0.740531  0.042061  0.010779     0\n",
       "\n",
       "[1514 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_fech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium\n",
    "from ddpg_tf2 import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Please provide to Input a `shape` or a `tensor` or a `type_spec` argument. Note that `shape` does not include the batch dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m agent \u001b[39m=\u001b[39m Agent(input_dims \u001b[39m=\u001b[39;49m env\u001b[39m.\u001b[39;49mobservation_space\u001b[39m.\u001b[39;49mshape,\\\n\u001b[0;32m      2\u001b[0m    env \u001b[39m=\u001b[39;49m env, n_actions \u001b[39m=\u001b[39;49menv\u001b[39m.\u001b[39;49maction_space\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m])\n",
      "File \u001b[1;32mc:\\Users\\Renato\\Desktop\\desafio_quant\\desafio_quant_2023\\ddpg_tf2.py:22\u001b[0m, in \u001b[0;36mAgent.__init__\u001b[1;34m(self, input_dims, alpha, beta, env, gamma, n_actions, max_size, tau, fc1, fc2, batch_size, noise)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_action \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39maction_space\u001b[39m.\u001b[39mhigh[\u001b[39m0\u001b[39m]\n\u001b[0;32m     20\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_action \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39maction_space\u001b[39m.\u001b[39mlow[\u001b[39m0\u001b[39m]\n\u001b[1;32m---> 22\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactor \u001b[39m=\u001b[39m ActorNetwork(n_actions\u001b[39m=\u001b[39;49mn_actions, name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mactor\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     23\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcritic \u001b[39m=\u001b[39m CriticNetwork(name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcritic\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_actor \u001b[39m=\u001b[39m ActorNetwork(n_actions\u001b[39m=\u001b[39mn_actions, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtarget_actor\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Renato\\Desktop\\desafio_quant\\desafio_quant_2023\\networks.py:45\u001b[0m, in \u001b[0;36mActorNetwork.__init__\u001b[1;34m(self, n_actions, fc1_dims, fc2_dims, name, chkpt_dir)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheckpoint_dir \u001b[39m=\u001b[39m chkpt_dir\n\u001b[0;32m     42\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheckpoint_file \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheckpoint_dir,\\\n\u001b[0;32m     43\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_name \u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_ddpg.h5\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 45\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc0 \u001b[39m=\u001b[39m Input()\n\u001b[0;32m     46\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflatten \u001b[39m=\u001b[39m Flatten()\n\u001b[0;32m     47\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1 \u001b[39m=\u001b[39m Dense(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1_dims, activation \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Renato\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Renato\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\input_layer.py:434\u001b[0m, in \u001b[0;36mInput\u001b[1;34m(shape, batch_size, name, dtype, sparse, tensor, ragged, type_spec, **kwargs)\u001b[0m\n\u001b[0;32m    424\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    425\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mOnly provide the `shape` OR `batch_input_shape` argument \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    426\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mto Input, not both at the same time.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    427\u001b[0m     )\n\u001b[0;32m    428\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    429\u001b[0m     batch_input_shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    430\u001b[0m     \u001b[39mand\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    431\u001b[0m     \u001b[39mand\u001b[39;00m tensor \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    432\u001b[0m     \u001b[39mand\u001b[39;00m type_spec \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    433\u001b[0m ):\n\u001b[1;32m--> 434\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    435\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease provide to Input a `shape` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    436\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mor a `tensor` or a `type_spec` argument. Note that \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    437\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`shape` does not include the batch \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    438\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdimension.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    439\u001b[0m     )\n\u001b[0;32m    440\u001b[0m \u001b[39mif\u001b[39;00m kwargs:\n\u001b[0;32m    441\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    442\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized keyword arguments: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(kwargs\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    443\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Please provide to Input a `shape` or a `tensor` or a `type_spec` argument. Note that `shape` does not include the batch dimension."
     ]
    }
   ],
   "source": [
    "agent = Agent(input_dims = env.observation_space.shape,\\\n",
    "   env = env, n_actions =env.action_space.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Retorno 0.0\n"
     ]
    }
   ],
   "source": [
    "obs,_ = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Exception encountered when calling layer 'actor_network' (type ActorNetwork).\n\n'KerasTensor' object is not callable\n\nCall arguments received by layer 'actor_network' (type ActorNetwork):\n  â€¢ state=tf.Tensor(shape=(4, 7), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m agent\u001b[39m.\u001b[39;49mactor(obs)\n",
      "File \u001b[1;32mc:\\Users\\Renato\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Renato\\Desktop\\desafio_quant\\desafio_quant_2023\\networks.py:52\u001b[0m, in \u001b[0;36mActorNetwork.call\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, state):\n\u001b[1;32m---> 52\u001b[0m   input_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc0(state)\n\u001b[0;32m     53\u001b[0m   prob \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflatten(input_layer)\n\u001b[0;32m     54\u001b[0m   prob \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1(state)\n",
      "\u001b[1;31mTypeError\u001b[0m: Exception encountered when calling layer 'actor_network' (type ActorNetwork).\n\n'KerasTensor' object is not callable\n\nCall arguments received by layer 'actor_network' (type ActorNetwork):\n  â€¢ state=tf.Tensor(shape=(4, 7), dtype=float32)"
     ]
    }
   ],
   "source": [
    "agent.actor(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xxxxxx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m agent \u001b[39m=\u001b[39m Agent(input_dims \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mobservation_space\u001b[39m.\u001b[39mshape,\\\n\u001b[0;32m      2\u001b[0m    env \u001b[39m=\u001b[39m env, n_actions \u001b[39m=\u001b[39menv\u001b[39m.\u001b[39maction_space\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[1;32m----> 5\u001b[0m xxxxxx\n\u001b[0;32m      6\u001b[0m n_games \u001b[39m=\u001b[39m \u001b[39m250\u001b[39m\n\u001b[0;32m      7\u001b[0m figure_file \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mplots/pendulum.png\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xxxxxx' is not defined"
     ]
    }
   ],
   "source": [
    "agent = Agent(input_dims = env.observation_space.shape,\\\n",
    "   env = env, n_actions =env.action_space.shape[0])\n",
    "\n",
    "n_games = 250\n",
    "figure_file = 'plots/pendulum.png'\n",
    "best_score = env.reward_range[0]\n",
    "score_history = []\n",
    "load_checkpoint = False\n",
    "\n",
    "if load_checkpoint:\n",
    "  n_steps = 0\n",
    "  while n_steps <= agent.batch_size:\n",
    "    observation, info = env.reset()\n",
    "    action = env.action_space.sample()\n",
    "    observation_, reward, _, done ,info = env.step(action)\n",
    "    agent.remember(observation, action, reward, observation_, done)\n",
    "    n_steps +=1\n",
    "    agent.learn()\n",
    "    agent.load_models()\n",
    "    evaluate = True\n",
    "else:\n",
    "  evaluate = False\n",
    "\n",
    "for i in range(n_games):\n",
    "  observation, info = env.reset()\n",
    "  done = False\n",
    "  score = 0\n",
    "  while not done:\n",
    "    #print(score)\n",
    "    action = agent.choose_action(observation, evaluate)\n",
    "    observation_, reward, _ ,done ,info = env.step(action)\n",
    "    score += reward\n",
    "    agent.remember(observation, action, reward, observation_, done)\n",
    "    #print(done)\n",
    "    if not load_checkpoint:\n",
    "      agent.learn()\n",
    "    observation = observation_\n",
    "  score_history.append(score)\n",
    "  avg_score = np.mean(score_history[-100:])\n",
    "\n",
    "  if avg_score > best_score:\n",
    "    best_score = avg_score\n",
    "    if not load_checkpoint:\n",
    "      agent.save_models()\n",
    "\n",
    "  print('episode ', i, 'score %.1f' % score,'avg score %1f' % avg_score )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
